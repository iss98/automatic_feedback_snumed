from model import *
from transformers import AutoTokenizer
import streamlit as st
import torch
import numpy as np
import tensorflow as tf
import sentencepiece as spm
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sample_answer import *

st.header(":teacher: í”¼ë“œë°± ë°©ì•ˆ 1 : ë¬¸í•­1-7")
st.subheader("í”¼ë“œë°± ê³¼ì •")
st.write(":one: ì§€ì‹ìš”ì†Œ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ í•™ìƒì´ ê°€ì§„ ì§€ì‹ìš”ì†Œ ë¶„ì„")
st.write(":two: í•™ìƒì´ ê°€ì§„ ì§€ì‹ìš”ì†Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”¼ë“œë°± ì œê³µ")
st.write(":three: ë£¨ë¸Œë¦­ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ê³„ë³„ íŒíŠ¸ ì œê³µ")
st.subheader("ë¬¸í•­")
st.markdown("$$ (2^4)^x \\times (2^2)^x=2^3 \\times 2^{3x} $$ì¼ ë•Œ, ìì—°ìˆ˜ $$x$$ì˜ ê°’ì„ êµ¬í•˜ì‹œì˜¤.")

response = st.text_input('ë‹µì•ˆ :', key='answer_input_1_7')

#ëª¨ë¸ì˜ ì´ë¦„ ì •í•˜ê¸°
model_name_1_7 = "1-7_att_sp_140" #ëª¨ë¸ ì´ë¦„ ë„£ì–´ì£¼ê¸° í™•ì¥ìëŠ” ë„£ì§€ë§ê¸°!
#ëª¨ë¸ì— ë§ëŠ” hyperparameter ì„¤ì •
vs = 140 #vocab size
emb = 16 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
hidden = 32 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
nh = 4 #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
device = "cpu" #default ê°’ ì§€ì • ì•ˆí–ˆìœ¼ë©´ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë¨
max_len = 100
#output_d ì„¤ì •
output_d_1_7 = 3 #ìê¸°ì˜ ëª¨ë¸ì— ë§ëŠ” output_dêµ¬í•˜ê¸° (ì§€ì‹ìš”ì†Œ ê°œìˆ˜)
c = cfg(vs=vs, emb=emb, hidden=hidden, nh=nh, device=device)

model_1_7 = ATTModel(output_d_1_7, c) #ATTModel ì“°ëŠ”ê²½ìš°

model_1_7.load_state_dict(torch.load("./save/"+model_name_1_7+".pt"))

#ìì‹ ì—ê²Œ ë§ëŠ” ëª¨ë¸ë¡œ ë¶€ë¥´ê¸°
tokenizer_1_7 = AutoTokenizer.from_pretrained("./save/"+model_name_1_7) #sp tokenizer ì“°ëŠ” ê²½ìš°


enc = tokenizer_1_7(response)["input_ids"] #sp tokenizer
l = len(enc)
if l < max_len :
    pad = (max_len - l) * [0] + enc
else : pad = enc[l-max_len:]
pad_ten = torch.tensor(pad)
pad_ten = pad_ten.reshape(1,max_len)
y = model_1_7(pad_ten)
label_1_7 = y.squeeze().detach().cpu().numpy().round()

if st.button('ğŸ‘€í”¼ë“œë°± ë°›ê¸°', key='button1_7_1'):
    
    #outputì°¨ì›ì— ë§ì¶”ì–´ í”¼ë“œë°± ë„£ê¸°
    
    st.write(response)
    if len(label_1_7) >= 3:
        if label_1_7[0] == 1 and label_1_7[1] == 1 and label_1_7[2] == 1:
            st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜!', icon="âœ…")   
        elif label_1_7[0] == 1 and label_1_7[1] == 1 and label_1_7[2] == 0:
            st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        elif label_1_7[0] == 1 and label_1_7[1] == 0 and label_1_7[2] == 0:
            st.success('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        elif label_1_7[0] == 0 and label_1_7[1] == 1 and label_1_7[2] == 0:
            st.success('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        elif label_1_7[2] == 0 and label_1_7[2] == 0 and label_1_7[2] == 1:
            st.success('ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ì´í•´í•˜ê³  ìˆêµ¬ë‚˜! ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì˜¬ë°”ë¥´ê²Œ ì ìš©í•´ì„œ í’€ì´ë¥¼ ì™„ì„±í•´ë³´ì!', icon="â„¹ï¸")
        else:
            st.info('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±, ê±°ë“­ì œê³±ì˜ ê³±ì…ˆ, ì¼ì°¨ë°©ì •ì‹ í’€ì´ë¥¼ ë³µìŠµí•˜ì„¸ìš”!', icon="âš ï¸")

if st.button('â“íŒíŠ¸1ï¸âƒ£', key='button1_7_2'):
    st.write('ë°‘ì´ 2ë¡œ ê°™ìœ¼ë‹ˆ, ì§€ìˆ˜ë¥¼ ì •ë¦¬í•˜ì„¸ìš”!')

if st.button('â“íŒíŠ¸2ï¸âƒ£', key='button1_7_3'):
    st.write('ê±°ë“­ì œê³±ì˜ ê±°ë“­ì œê³±ì„ ì ìš©í•´ì„œ ì‹ì„ ì •ë¦¬í•˜ì„¸ìš”!')

if st.button('â“íŒíŠ¸3ï¸âƒ£', key='button1_7_4'):
    st.write('ê±°ë“­ì œê³±ì˜ ê³±ì…ˆì„ ì ìš©í•´ì„œ ì‹ì„ ì •ë¦¬í•˜ì„¸ìš”!')

if st.button('ğŸ’¯ëª¨ë²”ë‹µì•ˆ', key='button1_7_5'):
    image_path = "save/1-7 ëª¨ë²”ë‹µì•ˆ.png-.png"
    st.image(image_path, caption='1-7ëª¨ë²”ë‹µì•ˆ')
